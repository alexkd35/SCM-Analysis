{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007eb6cf",
   "metadata": {},
   "source": [
    "# Supply Chain Data Cleaning\n",
    "#### Objective: Clean the dirty dataset to prepare for reliable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1690c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ccc073a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Summary of Key Findings for Data Cleaning\n",
      "\n",
      "1. **Missing Values**\n",
      "- Shipping costs: 5 missing values\n",
      "- Customer demographics: 6 missing values\n",
      "\n",
      "2. **Data Type Issues**\n",
      "- Availability appears to be stored as string\n",
      "- Needs conversion to integer\n",
      "\n",
      "3. **Duplicate Rows**\n",
      "- 1 duplicated row detected\n",
      "\n",
      "4. **Outliers**\n",
      "- Shipping times contains a negative value (-5)\n",
      "- Defect rates includes an extreme value of 100\n",
      "\n",
      "5. **Inconsistent Categories**\n",
      "- Transportation modes: lowercase values (e.g. \"road\")\n",
      "- Shipping carriers: extra spaces (e.g. \"DHL \")\n",
      "\n",
      "6. **Potential Redundant Columns**\n",
      "- Lead time and Lead times have the same number of unique values – further check needed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Findings from first document\n",
    "with open(\"C:/Users/User/OneDrive/DS/Projekte/SCM Analysis/data/explanations/key_findings_exploration.md\", \"r\") as f:\n",
    "    content = f.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f49f6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw (dirty) dataset\n",
    "df = pd.read_csv(\"C:/Users/User/OneDrive/DS/Projekte/SCM Analysis/data/supply_chain_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd14a88e",
   "metadata": {},
   "source": [
    "1. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38526f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Product type               0\n",
      "SKU                        0\n",
      "Price                      0\n",
      "Availability               0\n",
      "Number of products sold    0\n",
      "Revenue generated          0\n",
      "Customer demographics      6\n",
      "Stock levels               0\n",
      "Lead times                 0\n",
      "Order quantities           0\n",
      "Shipping times             0\n",
      "Shipping carriers          0\n",
      "Shipping costs             5\n",
      "Supplier name              0\n",
      "Location                   0\n",
      "Lead time                  0\n",
      "Production volumes         0\n",
      "Manufacturing lead time    0\n",
      "Manufacturing costs        0\n",
      "Inspection results         0\n",
      "Defect rates               0\n",
      "Transportation modes       0\n",
      "Routes                     0\n",
      "Costs                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for missing values -> assumption from the first document\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4ccf5",
   "metadata": {},
   "source": [
    "- We used the median to fill missing shipping costs because it is not effected by extreme values. Mean could be pulled up by very high shipping prices, but the median stays more stable.\n",
    "- We filled missing customer demographics with \"Unknown\" because we don’t had enough information to guess the real value. It’s better to keep the data than remove the whole row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7f1620ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'Shipping costs' with the median\n",
    "median_shipping_cost = df['Shipping costs'].median()\n",
    "df['Shipping costs'] = df['Shipping costs'].fillna(median_shipping_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e498b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'Customer demographics' with 'Unknown'\n",
    "df['Customer demographics'] = df['Customer demographics'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d33c2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Product type               0\n",
      "SKU                        0\n",
      "Price                      0\n",
      "Availability               0\n",
      "Number of products sold    0\n",
      "Revenue generated          0\n",
      "Customer demographics      0\n",
      "Stock levels               0\n",
      "Lead times                 0\n",
      "Order quantities           0\n",
      "Shipping times             0\n",
      "Shipping carriers          0\n",
      "Shipping costs             0\n",
      "Supplier name              0\n",
      "Location                   0\n",
      "Lead time                  0\n",
      "Production volumes         0\n",
      "Manufacturing lead time    0\n",
      "Manufacturing costs        0\n",
      "Inspection results         0\n",
      "Defect rates               0\n",
      "Transportation modes       0\n",
      "Routes                     0\n",
      "Costs                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check again for missing values -> assumption from the first document\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111d9dcf",
   "metadata": {},
   "source": [
    "2. Duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1c02da5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found: 1\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Duplicate rows found: {duplicates}\")\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b1636",
   "metadata": {},
   "source": [
    "3. Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "99034925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fix data types\n",
    "# 'Availability' might be object due to dirty data – try converting it to numeric\n",
    "df['Availability'] = pd.to_numeric(df['Availability'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "676201e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After coercion, check again for nulls\n",
    "df['Availability'] = df['Availability'].fillna(df['Availability'].median())\n",
    "df['Availability'] = df['Availability'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c75cff",
   "metadata": {},
   "source": [
    "4. Categorical Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "84857654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Standardize categorical text columns\n",
    "# Remove trailing spaces and unify formatting in some key columns\n",
    "df['Shipping carriers'] = df['Shipping carriers'].str.strip()\n",
    "df['Transportation modes'] = df['Transportation modes'].str.strip().str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d291be",
   "metadata": {},
   "source": [
    "5. Outlier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5a493ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Outlier handling\n",
    "# Remove negative values in 'Shipping times'\n",
    "df = df[df['Shipping times'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c1618cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap extreme defect rates at 99th percentile\n",
    "q_high = df['Defect rates'].quantile(0.99)\n",
    "df['Defect rates'] = np.where(df['Defect rates'] > q_high, q_high, df['Defect rates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab5218",
   "metadata": {},
   "source": [
    "6. Duplicated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8bf68f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns 'Lead time' and 'Lead times' differ review needed.\n"
     ]
    }
   ],
   "source": [
    "# 6. Check for duplicate columns or suspicious overlap\n",
    "# Example: Check if 'Lead time' and 'Lead times' are the same\n",
    "if df['Lead time'].equals(df['Lead times']):\n",
    "    print(\"Columns 'Lead time' and 'Lead times' are identical.\")\n",
    "    df.drop(columns=['Lead times'], inplace=True)\n",
    "else:\n",
    "    print(\"Columns 'Lead time' and 'Lead times' differ review needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620d011",
   "metadata": {},
   "source": [
    "7. Final Safety Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "75f26b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99 entries, 0 to 99\n",
      "Data columns (total 24 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Product type             99 non-null     object \n",
      " 1   SKU                      99 non-null     object \n",
      " 2   Price                    99 non-null     float64\n",
      " 3   Availability             99 non-null     int32  \n",
      " 4   Number of products sold  99 non-null     int64  \n",
      " 5   Revenue generated        99 non-null     float64\n",
      " 6   Customer demographics    99 non-null     object \n",
      " 7   Stock levels             99 non-null     int64  \n",
      " 8   Lead times               99 non-null     int64  \n",
      " 9   Order quantities         99 non-null     int64  \n",
      " 10  Shipping times           99 non-null     int64  \n",
      " 11  Shipping carriers        99 non-null     object \n",
      " 12  Shipping costs           99 non-null     float64\n",
      " 13  Supplier name            99 non-null     object \n",
      " 14  Location                 99 non-null     object \n",
      " 15  Lead time                99 non-null     int64  \n",
      " 16  Production volumes       99 non-null     int64  \n",
      " 17  Manufacturing lead time  99 non-null     int64  \n",
      " 18  Manufacturing costs      99 non-null     float64\n",
      " 19  Inspection results       99 non-null     object \n",
      " 20  Defect rates             99 non-null     float64\n",
      " 21  Transportation modes     99 non-null     object \n",
      " 22  Routes                   99 non-null     object \n",
      " 23  Costs                    99 non-null     float64\n",
      "dtypes: float64(6), int32(1), int64(8), object(9)\n",
      "memory usage: 18.9+ KB\n",
      "None\n",
      "\n",
      "Remaining missing values:\n",
      "Product type               0\n",
      "SKU                        0\n",
      "Price                      0\n",
      "Availability               0\n",
      "Number of products sold    0\n",
      "Revenue generated          0\n",
      "Customer demographics      0\n",
      "Stock levels               0\n",
      "Lead times                 0\n",
      "Order quantities           0\n",
      "Shipping times             0\n",
      "Shipping carriers          0\n",
      "Shipping costs             0\n",
      "Supplier name              0\n",
      "Location                   0\n",
      "Lead time                  0\n",
      "Production volumes         0\n",
      "Manufacturing lead time    0\n",
      "Manufacturing costs        0\n",
      "Inspection results         0\n",
      "Defect rates               0\n",
      "Transportation modes       0\n",
      "Routes                     0\n",
      "Costs                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Final sanity check\n",
    "print(\"\\nCleaned DataFrame info:\")\n",
    "print(df.info())\n",
    "print(\"\\nRemaining missing values:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8a2a66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "# df.to_csv(\"../data/supply_chain_data_cleaned.csv\", index=False)\n",
    "# print(\"\\n Cleaned dataset saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
